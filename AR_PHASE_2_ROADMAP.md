# AR Implementation Roadmap - Phase 2 Details

## ðŸ“‹ Phase 2A: Android ARCore Implementation

### Timeline: 1-2 Days
### Difficulty: Medium (requires Android knowledge)
### Priority: HIGH

### Prerequisites Checklist
- [ ] Android SDK 21+ installed
- [ ] Google Play Services AR installed
- [ ] Google Play Services installed on target device
- [ ] Device supports ARCore (Check: https://developers.google.com/ar/devices)
- [ ] `arcore_flutter_plugin` dependency in pubspec.yaml
- [ ] `permission_handler` ^10.4.5 in pubspec.yaml

### Implementation Steps

#### Step 1: Setup Android Permissions (30 min)
**File:** `android/app/src/main/AndroidManifest.xml`

Checklist:
- [ ] Add `<uses-permission android:name="android.permission.CAMERA" />`
- [ ] Add `<uses-feature android:name="android.hardware.camera.ar" />`
- [ ] Verify hardware acceleration enabled in Activity
- [ ] Test: `flutter analyze` â†’ 0 errors

**Commands:**
```bash
flutter clean
flutter pub get
flutter analyze
```

#### Step 2: Update Build Configuration (20 min)
**File:** `android/app/build.gradle`

Checklist:
- [ ] Set `minSdkVersion 21` (ARCore requirement)
- [ ] Add ARCore dependency: `com.google.ar:core:1.42.0`
- [ ] Add ARCore plugin if needed
- [ ] Test: Build succeeds

**Commands:**
```bash
cd android
./gradlew clean
cd ..
flutter pub get
```

#### Step 3: Request Runtime Permissions (1 hour)
**File:** `lib/src/modules/ar/services/ar_service.dart`

Checklist:
- [ ] Import `permission_handler`
- [ ] Add `requestCameraPermission()` method
- [ ] Handle denied/permanent denial cases
- [ ] Call permission before `initialize()`
- [ ] Test: Permission dialog appears

**Code Template:**
```dart
Future<void> requestCameraPermission() async {
  final status = await Permission.camera.request();
  
  if (status.isDenied) {
    throw ARException(
      'Camera permission denied',
      code: 'PERMISSION_DENIED',
    );
  } else if (status.isPermanentlyDenied) {
    openAppSettings();
  }
}
```

#### Step 4: Replace Mock with Real ARCore Implementation (3-4 hours)
**File:** `lib/src/modules/ar/platform/android/android_ar_service.dart`

Checklist:
- [ ] Initialize ArFlutterPlugin
- [ ] Create ArSession with config
- [ ] Add frame listener
- [ ] Extract plane data from frames
- [ ] Implement hitTest() with real coordinates
- [ ] Implement placeObject() with anchors
- [ ] Handle session pause/resume/stop
- [ ] Test: Planes appear after 1-3 sec
- [ ] Test: Tap places objects
- [ ] Test: Objects persist and update

**Key Methods to Implement:**
```
- initialize()
  â””â”€ Create ArFlutterPlugin
  â””â”€ Check ARCore availability
  
- startSession()
  â””â”€ Create ArSession
  â””â”€ Configure plane detection
  â””â”€ Start frame listener
  
- _onArFrame()
  â””â”€ Extract updated planes
  â””â”€ Emit planesStream
  
- hitTest(screenX, screenY)
  â””â”€ Convert to AR coordinates
  â””â”€ Test intersection
  â””â”€ Return ARHitTestResult
  
- placeObject(ARObject)
  â””â”€ Create anchor
  â””â”€ Add to scene
  â””â”€ Store reference
  
- updateObjectTransform()
  â””â”€ Update anchor position
  â””â”€ Redraw
  
- removeObject()
  â””â”€ Remove anchor
  â””â”€ Cleanup
  
- dispose()
  â””â”€ Pause session
  â””â”€ Close resources
```

#### Step 5: Testing on Real Device (1-2 hours)
**Prerequisites:**
- [ ] Android device with ARCore support
- [ ] USB cable connected
- [ ] Developer mode enabled
- [ ] USB debugging enabled

**Commands:**
```bash
# List connected devices
adb devices

# Check ARCore support
adb shell getprop ro.build.product

# Run app
flutter run -d <device_id>

# View logs
adb logcat | grep flutter
```

**Test Cases:**
- [ ] App opens without crash
- [ ] Camera permission dialog appears
- [ ] After permission: camera view shows
- [ ] After 1-3 seconds: floor plane detected
- [ ] Tap on screen: object appears
- [ ] Tap on object: outline shows
- [ ] Pinch gesture: object scales
- [ ] Two-finger rotation: object rotates
- [ ] Drag: object moves
- [ ] Delete button: object disappears

**Debugging:**
If planes not detected:
1. Ensure good lighting (not too dark)
2. Ensure surface has texture (not plain white)
3. Move device slowly
4. Try different surfaces (floor, wall, table)
5. Check logs: `adb logcat | grep ARCore`

---

## ðŸ“‹ Phase 2B: iOS ARKit Implementation

### Timeline: 1-2 Days
### Difficulty: Medium-High (requires iOS/Xcode knowledge)
### Priority: HIGH

### Prerequisites Checklist
- [ ] iOS 14.3+ device (A9 chip or newer)
- [ ] Xcode 13+ installed
- [ ] Apple Developer account
- [ ] CocoaPods installed
- [ ] `arkit_flutter_plugin` dependency in pubspec.yaml
- [ ] `permission_handler` ^10.4.5 in pubspec.yaml

### Implementation Steps

#### Step 1: Update iOS Podfile (30 min)
**File:** `ios/Podfile`

Checklist:
- [ ] Update post_install hook
- [ ] Add GCC_PREPROCESSOR_DEFINITIONS
- [ ] Include PERMISSION_CAMERA=1
- [ ] Include PERMISSION_SENSORS=1
- [ ] Run `pod install --repo-update`

**Key Changes:**
```ruby
post_install do |installer|
  installer.pods_project.targets.each do |target|
    flutter_additional_ios_build_settings(target)
    target.build_configurations.each do |config|
      config.build_settings['GCC_PREPROCESSOR_DEFINITIONS'] ||= [
        '$(inherited)',
        'PERMISSION_CAMERA=1',
        'PERMISSION_SENSORS=1',
      ]
    end
  end
end
```

#### Step 2: Update Info.plist (20 min)
**File:** `ios/Runner/Info.plist`

Checklist:
- [ ] Add NSCameraUsageDescription
- [ ] Add NSLocationWhenInUseUsageDescription
- [ ] Add NSMotionUsageDescription
- [ ] Verify CFBundleVersion set
- [ ] Test: No build errors

**Key Entries:**
```xml
<key>NSCameraUsageDescription</key>
<string>We need camera for AR features</string>

<key>NSLocationWhenInUseUsageDescription</key>
<string>Location improves AR accuracy</string>

<key>NSMotionUsageDescription</key>
<string>Motion data for AR tracking</string>
```

#### Step 3: Update Build Configuration (20 min)
**File:** `ios/Podfile` + `ios/Runner.xcodeproj/project.pbxproj`

Checklist:
- [ ] Set minimum deployment target to 14.3
- [ ] Enable code signing
- [ ] Set team ID
- [ ] Run `pod install --repo-update`

**Commands:**
```bash
cd ios
pod install --repo-update
cd ..
flutter clean
flutter pub get
```

#### Step 4: Request Runtime Permissions (1 hour)
**File:** `lib/src/modules/ar/services/ar_service.dart`

Same as Android - create `requestCameraPermission()` method

#### Step 5: Replace Mock with Real ARKit Implementation (3-4 hours)
**File:** `lib/src/modules/ar/platform/ios/ios_ar_service.dart`

Checklist:
- [ ] Initialize ARKitController
- [ ] Create ARSession
- [ ] Configure plane detection (horizontal + vertical)
- [ ] Setup anchor listener
- [ ] Extract plane data
- [ ] Implement hitTest() with ARKit coordinates
- [ ] Implement placeObject() with SCNNode
- [ ] Handle session pause/resume/stop
- [ ] Test: Planes appear
- [ ] Test: Tap places objects
- [ ] Test: Light estimation works

**Key Methods:**
```
- initialize()
  â””â”€ Check ARKit availability
  â””â”€ Verify iOS 14.3+
  
- startSession()
  â””â”€ Create ARSession
  â””â”€ Set plane detection
  â””â”€ Setup anchor callbacks
  
- _updateDetectedPlanes()
  â””â”€ Extract plane anchors
  â””â”€ Emit planesStream
  
- hitTest(screenX, screenY)
  â””â”€ Convert screen to AR coords
  â””â”€ Test against planes
  â””â”€ Return ARHitTestResult
  
- placeObject(ARObject)
  â””â”€ Create SCNNode
  â””â”€ Add to ARView scene
  â””â”€ Create anchor
  
- updateObjectTransform()
  â””â”€ Update SCNNode transform
  â””â”€ Update anchor
  
- removeObject()
  â””â”€ Remove SCNNode
  â””â”€ Remove anchor
  
- dispose()
  â””â”€ Pause ARSession
  â””â”€ Cleanup resources
```

#### Step 6: Testing on Real Device (1-2 hours)
**Prerequisites:**
- [ ] iPhone/iPad with A9+ chip running iOS 14.3+
- [ ] Connected via USB or WiFi
- [ ] Xcode project opened
- [ ] Development certificate installed

**Commands:**
```bash
# Open iOS project
open ios/Runner.xcworkspace

# Run from Xcode or terminal
flutter run -d ios
```

**Test Cases:**
- [ ] App opens without crash
- [ ] Camera permission dialog
- [ ] After permission: camera view shows
- [ ] Plane detection starts (wait 2-3 sec)
- [ ] Horizontal planes (floor, table) detected
- [ ] Vertical planes (walls) detected
- [ ] Tap: object placed correctly
- [ ] Object orientation correct (snapped to plane)
- [ ] Light estimation affects object appearance
- [ ] Gestures work (pinch, rotate, drag)

---

## ðŸ“‹ Phase 2C: Web WebXR Implementation

### Timeline: 1 Day
### Difficulty: Medium (requires WebXR/Babylon.js knowledge)
### Priority: MEDIUM

### Prerequisites Checklist
- [ ] Chrome 79+ or Firefox 55+ (WebXR support)
- [ ] HTTPS enabled or localhost
- [ ] Babylon.js CDN accessible
- [ ] WebXR Polyfill available
- [ ] Flutter web build configured

### Implementation Steps

#### Step 1: Update web/index.html (20 min)
**File:** `web/index.html`

Checklist:
- [ ] Add Babylon.js CDN (v5+)
- [ ] Add WebXR Polyfill
- [ ] Add canvas element
- [ ] Add status div elements
- [ ] Verify CDN links work

**Key Additions:**
```html
<script src="https://cdnjs.cloudflare.com/ajax/libs/babylonjs/5.53.0/babylon.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/webxr-polyfill@latest/build/webxr-polyfill.js"></script>
<canvas id="canvas"></canvas>
<div id="status-text">Not Started</div>
```

#### Step 2: Create Babylon.js Integration (2-3 hours)
**File:** `lib/src/modules/ar/platform/web/web_ar_service.dart`

Checklist:
- [ ] Initialize Babylon engine from canvas
- [ ] Create scene with camera
- [ ] Setup lighting (hemisphere + point light)
- [ ] Start render loop
- [ ] Handle window resize
- [ ] Test: Scene renders

**Key Methods:**
```
- initialize()
  â””â”€ Check WebXR support
  â””â”€ Initialize Babylon scene
  â””â”€ Setup lighting
  â””â”€ Start render loop
  
- _initializeBabylonScene()
  â””â”€ Get canvas
  â””â”€ Create engine
  â””â”€ Create scene
  â””â”€ Create camera
  
- _setupLighting()
  â””â”€ Add hemisphere light
  â””â”€ Add point lights
  â””â”€ Setup shadows
```

#### Step 3: Implement WebXR Session (1-2 hours)
**File:** `lib/src/modules/ar/platform/web/web_ar_service.dart`

Checklist:
- [ ] Request XR session
- [ ] Handle user permission
- [ ] Get reference space
- [ ] Connect Babylon camera to XR
- [ ] Test: Can start AR session

**Key Methods:**
```
- startSession()
  â””â”€ Request 'immersive-ar' session
  â””â”€ Get reference space
  â””â”€ Setup XR camera
  â””â”€ Start receiving XR frames
  
- _setupXRCamera()
  â””â”€ Get XR reference space
  â””â”€ Create Babylon camera
  â””â”€ Bind to XR tracking
```

#### Step 4: Implement Hit Testing (1 hour)
**File:** `lib/src/modules/ar/platform/web/web_ar_service.dart`

Checklist:
- [ ] Implement hitTest() with mock data
- [ ] Create mock planes (floor + wall)
- [ ] Test: Tap returns hit results
- [ ] Note: Real WebXR hit-test API for future

**Mock Implementation:**
```dart
Future<ARHitTestResult?> hitTest(double screenX, double screenY) async {
  // Convert screen to normalized coordinates
  final normalizedX = screenX / window.innerWidth!;
  final normalizedY = screenY / window.innerHeight!;
  
  // Return mock hit on floor plane
  return ARHitTestResult(
    id: DateTime.now().millisecondsSinceEpoch.toString(),
    hitPoint: Vector3(
      x: (normalizedX - 0.5) * 4,
      y: -0.5,
      z: -(normalizedY * 3 + 1),
    ),
    estimatedRotation: Quaternion.identity(),
    distance: 2.0,
    planeId: 'floor',
  );
}
```

#### Step 5: Implement Object Placement (1 hour)
**File:** `lib/src/modules/ar/platform/web/web_ar_service.dart`

Checklist:
- [ ] Create Babylon mesh for AR objects
- [ ] Apply materials and colors
- [ ] Add to scene
- [ ] Test: Objects appear in 3D view

**Key Methods:**
```
- placeObject(ARObject)
  â””â”€ Create Babylon.js mesh
  â””â”€ Apply material
  â””â”€ Set position
  â””â”€ Add to scene
  
- updateObjectTransform()
  â””â”€ Find mesh
  â””â”€ Update position/rotation/scale
  
- removeObject()
  â””â”€ Find and dispose mesh
```

#### Step 6: Testing in Browsers (1-2 hours)

**Prerequisites:**
- [ ] Chrome 79+ or Firefox 55+
- [ ] HTTPS enabled or using localhost
- [ ] WebXR device/simulator available

**Commands:**
```bash
# Development with hot reload
flutter run -d chrome --web-renderer=canvaskit

# Production build
flutter build web --release

# Serve locally with HTTPS (if needed)
npx http-server -p 8000 --ssl
```

**Test Cases:**
- [ ] Page loads without console errors
- [ ] "WebXR available" message in console
- [ ] Can start AR session (Chrome with AR device)
- [ ] Scene renders with lighting
- [ ] Can tap to place objects
- [ ] Objects visible in 3D
- [ ] Objects can be moved/rotated/scaled
- [ ] Performance: 60 FPS target
- [ ] No memory leaks on multiple placements

---

## ðŸŽ¯ Success Criteria for Each Phase

### Phase 2A (Android) - Complete When:
- [ ] ARCore planes detected automatically after app start
- [ ] User can tap to place objects
- [ ] Objects can be transformed (move/rotate/scale)
- [ ] Multiple objects can coexist
- [ ] Session can be paused and resumed
- [ ] No crashes or memory leaks
- [ ] Console: 0 errors, only info-level logs
- [ ] Compilation: `flutter analyze` â†’ 0 errors

### Phase 2B (iOS) - Complete When:
- [ ] ARKit planes detected (horizontal and vertical)
- [ ] User can tap to place objects
- [ ] Objects persist and transform correctly
- [ ] Light estimation affects rendering
- [ ] Session interruption handled gracefully
- [ ] No crashes or memory leaks
- [ ] Console: 0 errors
- [ ] Compilation: `flutter analyze` â†’ 0 errors

### Phase 2C (Web) - Complete When:
- [ ] Scene renders with proper lighting
- [ ] Mock planes visible in scene
- [ ] User can tap to place objects
- [ ] Objects appear in 3D space
- [ ] Babylon.js rendering smooth (60 FPS)
- [ ] No console errors or warnings
- [ ] Compilation: `flutter analyze` â†’ 0 errors

---

## ðŸš€ Deployment Checklist (After All Phases Complete)

### Before Commit
- [ ] All platforms: 0 compilation errors
- [ ] All platforms: `flutter test` passes
- [ ] All platforms: Performance targets met
- [ ] No hardcoded debug paths or credentials
- [ ] Proper error handling everywhere
- [ ] Comprehensive logging for debugging

### Android Deployment
- [ ] Build: `flutter build apk --release`
- [ ] Test on 3+ devices with different API levels
- [ ] Test on device with and without ARCore
- [ ] Check battery drain (target: < 10% per hour)
- [ ] Prepare for Google Play release

### iOS Deployment
- [ ] Build: `flutter build ios --release`
- [ ] Archive in Xcode
- [ ] Test on real device
- [ ] Check memory usage (target: < 50MB)
- [ ] Prepare for App Store release

### Web Deployment
- [ ] Build: `flutter build web --release`
- [ ] Test on Chrome, Firefox, Edge
- [ ] Verify HTTPS certificate
- [ ] Deploy to CDN or hosting service
- [ ] Monitor real-world performance

### GitHub
- [ ] Commit message: "feat(ar): Complete AR Phase 2 implementation"
- [ ] Include all platform implementations
- [ ] Update documentation
- [ ] Create release notes
- [ ] Tag version (e.g., v2.0.0)

---

## ðŸ“Š Progress Tracking

Current Status:
```
Phase 2A (Android ARCore):    â³ 30% (Stubs ready, real impl pending)
Phase 2B (iOS ARKit):         â³ 30% (Stubs ready, real impl pending)
Phase 2C (Web WebXR):         â³ 30% (Mocks ready, real impl pending)
```

Expected Timeline:
- Phase 2A: 2-3 days (Android ARCore)
- Phase 2B: 2-3 days (iOS ARKit)
- Phase 2C: 1-2 days (Web WebXR)
- Integration & Testing: 1-2 days
- **Total Phase 2: ~1 week**

**Total Module 2 AR:**
- Phase 1 (Foundation): âœ… COMPLETE
- Phase 2 (Platform Implementation): ðŸ”„ PENDING (this roadmap)
- Phase 3 (Advanced Features): â³ AFTER Phase 2
- **Estimated Total: 2-3 weeks**

---

## ðŸ“š Helpful Resources

### Android ARCore
- [ARCore Developer Guide](https://developers.google.com/ar/develop)
- [ARCore with Flutter](https://pub.dev/packages/arcore_flutter_plugin)
- [Device Support List](https://developers.google.com/ar/devices)

### iOS ARKit
- [ARKit Documentation](https://developer.apple.com/arkit/)
- [ARKit with Flutter](https://pub.dev/packages/arkit_flutter_plugin)

### Web WebXR
- [WebXR Specification](https://www.w3.org/TR/webxr/)
- [Babylon.js Documentation](https://doc.babylonjs.com/)
- [WebXR Browser Support](https://caniuse.com/webxr)

### Tools & Testing
- [ARCore Emulator Setup](https://developers.google.com/ar/develop/getting-started#supported_devices)
- [Babylon.js Playground](https://www.babylonjs-playground.com/)
- [WebXR Testing](https://immersive-web.github.io/webxr-samples/)

---

**Document Version:** 1.0
**Last Updated:** December 5, 2025
**Status:** Ready for Phase 2A Implementation
**Next Step:** "Implement Android ARCore full integration"
